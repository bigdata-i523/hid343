\documentclass[sigconf]{acmart}

\input{format/i523}

\begin{document}

\title{Income Prediction based on Machine Learning Techniques}

\author{Borga Edionse Usifo}
\affiliation{%
\institution{Indiana University}
\city{Bloomington} 
\state{Indiana} 
\postcode{47408}
}
\email{busifo@iu.edu}

\renewcommand{\shortauthors}{B. Usifo et al.}

\begin{abstract}

\end{abstract}

\keywords{i523, HID343, Manufacturing, Industry 4.0, Autonomous Decision in Manufacturing, Analytics in Manufacturing}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Importance of Data-Driven Approach in Manufacturing}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{How it related to big data analytics}

 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Machine Learning Algorithms to Consider}
We have multiple algorithms to consider when we are doing the supervised learning. Each algorithm has its benefits and drawbacks. We will consider several supervised machine learning algorithms for our predictions. The application we will use to implement these algorithms will be Python Scikit-Learn library. We will briefly explain each parameter included in these algorithms in Scikit-Learn.

\par First we`ll look at the Scikit-Learn in Python framework we will go through the advantages in Scikit-Learn how we can implement any machine learning in just couple of simple line of codes in Scikit-Learn. 

\subsection{Why Scikit-Learn?}
Scikit-learn developed by David Cournapeau in 2007. The development came from while he was working on summer code project for Google. After recognized and published by INRIA in 2010 project start the get more attention among worldwide. There are more than 30 active contributors and has secured several sponsorships from big technology companies\cite{www-machinelearningmystery}. ``It also has a goal of provide common algorithms to Python users through consistent interface\cite{www-oreily}``. Scikit-Learn consists of several elements to make analytical predictions. These elements are shown below\cite{www-analyticvidhya}:

\begin{itemize}
\item \textbf{\textit{\underline{Supervised Learning Algorithms:}}} One of the most fundamental reason that Scikit-Learn's popularity comes from highly available supervised learning algorithms. These algorithms vary from regression models to decision trees and many more\cite{www-analyticvidhya}. 
\item \textbf{\textit{\underline{Cross Validation:}}} Scikit-Learn includes various techniques to check the accuracy or any statistical measure between training and unseen testing set\cite{www-analyticvidhya}. 
\item \textbf{\textit{\underline{Unsupervised Learning Algorithms:}}} Scikit-Learn had also various algorithms to support many unsupervised algorithms some of these include clustering, factor analysis, and neural network analysis\cite{www-analyticvidhya}. 
\item \textbf{\textit{\underline{Various example data-sets:}}} Scikit-Learn comes with different data sets included in its package so users can start learning Scikit-Learn without the need of any data-sets\cite{www-analyticvidhya}. 
\item \textbf{\textit{\underline{Feature extraction:}}} It has rich feature for extracting images or text from data-sets\cite{www-analyticvidhya}.
\end{itemize}

\par Algorithms that we will investigate are shown below; we will go more deep analysis on each of these algorithms. 

\begin{itemize}
    \item \textit{Gaussian Naive Bayes}
    \item \textit{Decision Trees}
    \item \textit{K-Nearest Neighbors (KNN)}
    \item \textit{Stochastic Gradient Descent Classifier}
    \item \textit{Support Vector Machines}
    \item \textit{Logistic Regression} 
\end{itemize}

\subsection{Gaussian Naive Bayes}
Naive Bayes bring many beneficial features, it is widely popular among machine learning applications\cite{tapan-kumar}. Popularity of Naive Bayes comes from being able to handle large projects and data-sets faster than most algorithms\cite{tapan-kumar}. It also can handle complex data-sets with categorical and non-categorical inputs \cite{tapan-kumar}. Naive Bayes is based on probabilistic classifier of Bayesian theory. It's also popular way of doing text categorization\cite{www-wikipedia-naivebayes}. 
\par Term naive comes from it's method of use probability among categories which assumes of independence among given class of attributes. In other words, if we try to classify individuals from their email communications it will not take the order of words into account. Where as in English language we can tell the difference of sentence makes sense or not if we randomly re-order our words in the sentences. So it really doesn't understand the text, it only looks at word frequencies as a way to do the classification. This is why it is called ``Naive``.  As we states above Naive Bayes derives from Bayesian Theory where the dimensionality of inputs is relatively high. Bayesian Theorem is stated below \cite{Sayali}. 
\begin{equation}
P(C \mid X) = \frac{P(X \mid C) \times P(C)} {P(X)}
\end{equation}

Naive Bayes Classifier works as follows \cite{Sayali}:

Advantages of Naive Bayes:
\begin{itemize}
\item Faster classification time for training data-set.
\item Because of independent classification it improves classification performance.
\item Performance is relatively good. 
\end{itemize}

Disadvantages of Naive Bayes:

\begin{itemize}
\item Often it requires large number of data-sets to give adequate results.
\item On some occasions which is realative to data-sets it can give less accuracy.
\end{itemize}

\subsection{Decision Trees}



\subsection{Ensemble Methods}



\subsection{K-Nearest Neighbors (KNN)}



\subsection{Stochastic Gradient Descent Classifier}



\subsection{Support Vector Machines}
 


\subsection{Logistic Regression}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}

We presented the importance of smart manufacturing and Big Data based applications on Industry 4.0 (smart manufacturing). Insights about advantages of predictive maintenance, statistical control techniques, smart supply chain innovations had given. Several analytical approaches while using Big Data applications also had shown.

\begin{acks}

The author would like to thank Dr. Gregor von Laszewski for his support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 



\end{document}
